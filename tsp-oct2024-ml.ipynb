{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"},{"sourceId":7949759,"sourceType":"datasetVersion","datasetId":4675026}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-02T07:52:23.109260Z","iopub.execute_input":"2024-10-02T07:52:23.109753Z","iopub.status.idle":"2024-10-02T07:52:24.423326Z","shell.execute_reply.started":"2024-10-02T07:52:23.109691Z","shell.execute_reply":"2024-10-02T07:52:24.421759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- perform autogluon\n- perform optuna \n- perform decorator function ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\nimport os\n\n\nfrom sklearn import metrics\nfrom sklearn.metrics import *\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:27:56.672097Z","iopub.execute_input":"2024-10-02T08:27:56.672661Z","iopub.status.idle":"2024-10-02T08:27:56.785889Z","shell.execute_reply.started":"2024-10-02T08:27:56.672613Z","shell.execute_reply":"2024-10-02T08:27:56.784367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/playground-series-s4e10/sample_submission.csv')\ndf_0 = pd.read_csv('/kaggle/input/loan-approval-prediction/credit_risk_dataset.csv')\ndf_1 = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\n\nprint('\\n\\nTotal Null values in Train: ', df_1.isnull().sum().sum())\nprint('Total Null values in original data: ', df_0.isnull().sum().sum())\nprint('\\n\\nTotal Null values in Test: ', test.isnull().sum().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:39:18.619113Z","iopub.execute_input":"2024-10-02T08:39:18.619778Z","iopub.status.idle":"2024-10-02T08:39:18.853152Z","shell.execute_reply.started":"2024-10-02T08:39:18.619720Z","shell.execute_reply":"2024-10-02T08:39:18.851684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will combine the original dataset with the tabular dataset\n- drop the id from the tabular dataset \n- drop the rows that have null values or \n    - if there is some relation between the featires i will impute something later on ","metadata":{}},{"cell_type":"code","source":"train = pd.concat((df_1.drop(columns = ['id'], inplace = False), df_0)).dropna(how='any',axis=0) \ntest = test.drop(columns = ['id'])\nprint('train', train.shape, 'test', test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:39:24.630901Z","iopub.execute_input":"2024-10-02T08:39:24.631382Z","iopub.status.idle":"2024-10-02T08:39:24.685122Z","shell.execute_reply.started":"2024-10-02T08:39:24.631343Z","shell.execute_reply":"2024-10-02T08:39:24.683856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def uniqueValues(df):   \n    object_cols = df.select_dtypes(include = ['object']).columns\n    print('All the unique values in the dataset')\n    for cols in object_cols:\n        print(f\" -- {cols} has: {df[cols].nunique()}\")\n        if df[f'{cols}'].nunique() > 1000000:\n            print(f\" -- {cols} has: {df[cols].nunique()}, too many to list\")\n        else:\n            plt.figure(figsize=(10, 3))\n            sns.histplot(df[cols], kde = False) #, bins = 5)\n            plt.title(f\" {cols} has:\\n {df[cols].unique()}\")\n            plt.xlabel(f'{cols}')\n            plt.ylabel('Frequency')\n            plt.show()\n\n        print('\\n\\n') \n        \nuniqueValues(train)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:39:31.201892Z","iopub.execute_input":"2024-10-02T08:39:31.203201Z","iopub.status.idle":"2024-10-02T08:39:32.775413Z","shell.execute_reply.started":"2024-10-02T08:39:31.203119Z","shell.execute_reply":"2024-10-02T08:39:32.774355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dealing with categorical variables","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:39:32.777835Z","iopub.execute_input":"2024-10-02T08:39:32.778225Z","iopub.status.idle":"2024-10-02T08:39:32.783106Z","shell.execute_reply.started":"2024-10-02T08:39:32.778186Z","shell.execute_reply":"2024-10-02T08:39:32.782074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":">>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n...                    columns=['letter', 'number'])\n>>> print(df1)\n\n>>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n...                    columns=['letter', 'number'])\n>>> print(df2)\n\n>>> pd.concat([df1, df2], axis = 1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:39:32.784365Z","iopub.execute_input":"2024-10-02T08:39:32.784733Z","iopub.status.idle":"2024-10-02T08:39:32.808925Z","shell.execute_reply.started":"2024-10-02T08:39:32.784689Z","shell.execute_reply":"2024-10-02T08:39:32.807828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def featureEncoding(df, _type = None):\n    object_cols = df.select_dtypes(include = ['object']).columns\n    \n    if _type == 'one_hot':\n        obj_df = pd.get_dummies(df[object_cols], drop_first=True, dtype='int8')\n        combined_df = pd.concat([df.drop(columns = object_cols, axis = 1), obj_df], axis=1)\n        \n#     print(len(combined_df.columns))\n        \n    return combined_df\n\n\ndef featureScaling(df, _type = None):\n    scaler = MinMaxScaler()\n    \n    if _type == 'train':\n        x = df.drop(['loan_status'], axis = 1)\n        cols = x.columns\n        x = pd.DataFrame(scaler.fit_transform(x), columns = cols)\n        return x, df['loan_status']\n    elif _type == 'test':\n        cols = df.columns\n        x = pd.DataFrame(scaler.fit_transform(df), columns = cols)\n        return x\n    return \n    \n\nx, y = featureScaling(featureEncoding(train, 'one_hot'), 'train')\ntest_df = featureScaling(featureEncoding(test, 'one_hot'), 'test')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:42:24.733903Z","iopub.execute_input":"2024-10-02T08:42:24.734591Z","iopub.status.idle":"2024-10-02T08:42:24.876616Z","shell.execute_reply.started":"2024-10-02T08:42:24.734521Z","shell.execute_reply":"2024-10-02T08:42:24.875230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## basic model testing ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:27:14.807407Z","iopub.execute_input":"2024-10-02T08:27:14.808661Z","iopub.status.idle":"2024-10-02T08:27:14.954519Z","shell.execute_reply.started":"2024-10-02T08:27:14.808610Z","shell.execute_reply":"2024-10-02T08:27:14.953157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_prediction(model, x_train, x_test, y_train, y_test):\n    model.fit(x_train,y_train)\n    x_train_pred = model.predict(x_train)\n    x_test_pred = model.predict(x_test)\n    y_test_prob = model.predict_proba(x_test)[:, 1]\n\n    a = accuracy_score(y_train,x_train_pred)*100\n    b = accuracy_score(y_test,x_test_pred)*100\n    c = precision_score(y_test,x_test_pred)\n    d = recall_score(y_test,x_test_pred)\n    e = roc_auc_score(y_test, y_test_prob)\n    print(f\"Accuracy_Score of {model} model on Training Data is:\",a)\n    print(f\"Accuracy_Score of {model} model on Testing Data is:\",b)\n    print(f\"Precision Score of {model} model is:\",c)\n    print(f\"Recall Score of {model} model is:\",d)\n    print(f\"AUC Score of {model} model is:\", e)\n    print(\"\\n------------------------------------------------------------------------\")\n    print(f\"Confusion Matrix of {model} model is:\")\n    cm = confusion_matrix(y_test,x_test_pred)\n    plt.figure(figsize=(8,4))\n    sns.heatmap(cm,annot=True,fmt=\"g\",cmap=\"Greens\")\n    plt.show()\n    \n    return model\n\ndef testSubmisison(test, submission, model):\n    name = model.__class__.__name__\n    submission['loan_status'] = model.predict(test)\n    submission.to_csv(f'{name}_submission.csv', index = False)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:55:06.525784Z","iopub.execute_input":"2024-10-02T08:55:06.526322Z","iopub.status.idle":"2024-10-02T08:55:06.537963Z","shell.execute_reply.started":"2024-10-02T08:55:06.526269Z","shell.execute_reply":"2024-10-02T08:55:06.536520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nmodel = model_prediction(clf, x_train, x_test, y_train, y_test)\ntestSubmisison(test_df, sample_submission, model)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:55:08.355677Z","iopub.execute_input":"2024-10-02T08:55:08.356178Z","iopub.status.idle":"2024-10-02T08:55:09.511744Z","shell.execute_reply.started":"2024-10-02T08:55:08.356133Z","shell.execute_reply":"2024-10-02T08:55:09.510312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nclf = lgb.LGBMClassifier()\nmodel = model_prediction(clf, x_train, x_test, y_train, y_test)\ntestSubmisison(test_df, sample_submission, model)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:55:36.589606Z","iopub.execute_input":"2024-10-02T08:55:36.590122Z","iopub.status.idle":"2024-10-02T08:55:39.387432Z","shell.execute_reply.started":"2024-10-02T08:55:36.590073Z","shell.execute_reply":"2024-10-02T08:55:39.386278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators = 100)  \nmodel = model_prediction(clf, x_train, x_test, y_train, y_test)\ntestSubmisison(test_df, sample_submission, model)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:57:18.025045Z","iopub.execute_input":"2024-10-02T08:57:18.025596Z","iopub.status.idle":"2024-10-02T08:57:32.090680Z","shell.execute_reply.started":"2024-10-02T08:57:18.025551Z","shell.execute_reply":"2024-10-02T08:57:32.089682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}